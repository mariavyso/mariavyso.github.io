[{"content":"\u003ch5\u003eSummary: \u003cbr\u003eThis is the story of how I built a voice-to-text journaling app. Starting from a need to keep up with my thoughts, this project pushed my limits. I tackled tech choices, solved tricky problems, and learned loads – especially about keeping things simple and user-focused. Big learning curve, bigger rewards! \u003c/h5\u003e\n\u003cp\u003e\u003cbr\u003e\u003cstrong\u003eTools, I leaned on:\u003c/strong\u003e Expo, WhisperAI API, GCP.\u003c/p\u003e\n\u003cp\u003e\u003cbr\u003eThe code for this project is \u003ca href=\"https://github.com/mariavyso/journaling_app\"\u003ehere\u003c/a\u003e!\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e\u003cbr\u003eHave you ever felt like your thoughts are racing faster than your hands can write them down? As a Junior Software Engineer and a self-proclaimed journaling enthusiast, this was a constant struggle for me. That\u0026rsquo;s where my journey with this voice-to-text journaling app began.\u003c/p\u003e\n\u003cp\u003eIt all started with a simple yet intriguing challenge from my therapist: to explore journaling as a tool for self-discovery. In 2023, pen and paper seem archaic, but there\u0026rsquo;s something about writing down your thoughts that feels deeply personal. However, when my hand was cramped from trying to keep pace with my thoughts, I knew there had to be a better way. So I had an idea to create an app that could transcribe my monologue into written text and send it to the document with a timestamp, so I could go back and re-read it if I wanted.\u003c/p\u003e\n\u003cp\u003eI was aware of existing apps that offered similar features, but as someone with a product management background, the passion for crafting something tailored to my needs was irresistible. Plus, it was the perfect project to improve my skills and learn something new.\u003c/p\u003e\n\u003ch3 id=\"little-roadmap\"\u003eLittle Roadmap\u003c/h3\u003e\n\u003cp\u003eI decided to break the task into 4 phases:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eOutline the application’s core functions (1 Day)\u003c/li\u003e\n\u003cli\u003eResearch of the technologies (3 Day)\u003c/li\u003e\n\u003cli\u003eBuild an MVP (5 days)\u003c/li\u003e\n\u003cli\u003eFinalizing the product (5 days)\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eTo manage myself more effectively I added the approximate number of days that I planned to spend on each step, given that I have a full-time job.\u003c/p\u003e\n\u003cp\u003e\u003cbr\u003e\u003cdiv style=\"width:70%;height:0;padding-bottom:57%;position:relative;\"\u003e\n    \u003cimg src=\"https://media.giphy.com/media/toXKzaJP3WIgM/source.gif\" width=\"100%\" height=\"100%\" style=\"position:absolute\" frameBorder=\"0\"\u003e\n    \u003c/img\u003e\n  \u003c/div\u003e\n  \u003cp\u003e\u003ca href=\"https://giphy.com/gifs/toXKzaJP3WIgM\"\u003evia GIPHY\u003c/a\u003e\u003c/p\u003e\u003c/p\u003e\n\u003cbr\u003e\n\u003ch3 id=\"phase-1-core-functions-of-the-product\"\u003ePhase 1. Core functions of the product\u003c/h3\u003e\n\u003cp\u003eI was thinking about something simple, yet effective and decided on these functions:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eFrontend:\u003c/strong\u003e A button to start/stop audio recording and a timer.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eBackend:\u003c/strong\u003e Audio recording, transcription, and text integration into a document.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cbr\u003e\n\u003ch3 id=\"phase-2-research-of-the-technologies\"\u003ePhase 2. Research of the technologies\u003c/h3\u003e\n\u003cp\u003eI started my research with the frontend part since my experience in interface programming was limited to the Chrome extension (insert link to post). Fortunately, I have friends who have experience in mobile development and after a couple of interviews and googling, I decided to write a naive application, using the open-source platform Expo.\u003c/p\u003e\n\u003cp\u003eFor the backend part, I found two options for easy audio transcription:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eGoogle Cloud Speech-to-text API\u003c/li\u003e\n\u003cli\u003eWhisperAI API from OpenAI\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eAfter testing, WhisperAI emerged as the winner for its accuracy and cost-effectiveness.\u003c/p\u003e\n\u003cp\u003eSince the project was intended for personal use only, for the final step, I decided to use a Google Documents.\u003c/p\u003e\n\u003cp\u003eAt this step, I tried to run a quick test of the product, starting with the backend, since I have more experience in this area. Everything went quite successfully here. I recorded a couple of audio to test the script, transcribed them using the WhisperAI API, and sent the text to Google document.\u003c/p\u003e\n\u003cp\u003eTesting the frontend part was also quite easy - I had a button to turn the audio recording on and off and I could use Expo to record and then I could play this audio on my device.\u003c/p\u003e\n\u003cp\u003eAt this step, it seemed to me that everything was quite simple and I needed a couple more days to assemble a full-fledged MVP.\u003c/p\u003e\n\u003cbr\u003e\n\u003ch3 id=\"phase-3-the-mvp-challenge\"\u003ePhase 3. The MVP Challenge\u003c/h3\u003e\n\u003cp\u003eThis phase was a rollercoaster.\u003c/p\u003e\n\u003cp\u003eInspired by the success of those quick tests, I started with the frontend and wrote the code for the button, that turns the audio recording on and off and added the timer so I could see the duration of my record on the screen. (It was not fast, after this experience I no longer joke about the frontend)\nFor the backend, I decided that it would be great to store my audio recordings in the Google Storage Bucket and wrote a Google function that would be triggered by the new audio, that appeared in the bucket.\u003c/p\u003e\n\u003cp\u003eBut here I met an issue with the audio format and it turned out that Expo records audio in CAF format by default, and even if I specify MP3 in the recording settings, the WhisperAI API does not understand this format. So I added the ffmpeg library for audio reformatting. This helped, but a new issue arose.\u003c/p\u003e\n\u003cp\u003eAs it turns out, to send audio from Expo to the Google bucket, I need to either generate a token manually on the Google side and constantly update it, or register the application and configure it as a real app, which was not part of my plans either for the MVP nor for the real product. I was okay with having the app available through Expo Go and not having it in the Apple store ($99 per year and ongoing support of the app for other people wasn\u0026rsquo;t on my wishlist).\u003c/p\u003e\n\u003cp\u003eI left this question for step 4, which means that for now, I needed to copy the token and paste it to the Expo manually. The rest of the app worked well, the Google function triggered as soon as new audio appeared in the bucket, the WhisperAI API transcribed the text, and the text was inserted into the document, I was happy.\u003c/p\u003e\n\u003cbr\u003e\n\u003ch3 id=\"phase-4-crucial-pivot-and-finalizing-the-product\"\u003ePhase 4. Crucial pivot and finalizing the product\u003c/h3\u003e\n\u003cp\u003eTo solve the problem of generating a token, I turned to my mentor, who, by luck, is a senior software engineer. He suggested two options for solving the problem:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eRewrite the code so that audio is sent from Expo to the Google function via an HTTP request.\u003c/li\u003e\n\u003cli\u003eTry to generate a new JWT token inside of the Expo.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eOf course, I didn’t want to destroy my setup in Google Cloud, which I considered a genius and met my requirements, so I chose option 2 - generating a token and authentication inside Expo.\u003c/p\u003e\n\u003cp\u003eAs it turned out, this was challenging, because we have a ton of libraries in Python and JS for JWT signature generation, but somehow JS libraries didn’t work in my case.\n\u003cbr\u003e\nMy mentor became interested in solving this issue and offered some help with this and wrote a code that works for Expo and Google and I was over the moon because it finally worked.\u003c/p\u003e\n\u003cp\u003eAfter a couple of days of using the application for its intended purpose, I realized that after each click on the stop recording button I used to go and check the Google document to see if the audio transcript had been loaded into it. This was not convenient and I decided that I needed to display a message on the screen as soon as new text was loaded.\u003c/p\u003e\n\u003cp\u003eBut for incorporating this feature, It turned out that I needed one more authentication, and guess what I had to do\u0026hellip;\u003c/p\u003e\n\u003cbr\u003e\n\u003cdiv style=\"width:70%;height:0;padding-bottom:57%;position:relative;\"\u003e\n    \u003cimg src=\"https://media.giphy.com/media/GZLf5Njk1KGwU/source.gif\" width=\"100%\" height=\"100%\" style=\"position:absolute\" frameBorder=\"0\"\u003e\n    \u003c/img\u003e\n  \u003c/div\u003e\n  \u003cp\u003e\u003ca href=\"https://giphy.com/gifs/GZLf5Njk1KGwU\"\u003evia GIPHY\u003c/a\u003e\u003c/p\u003e\n\u003cbr\u003e\n\u003cp\u003eThis led to a crucial pivot: instead of storing audio, I decided to send it directly to the backend for processing. A challenging decision, but it streamlined the app and reduced complexity. Well, that is, I returned to the first option that my mentor suggested.\u003c/p\u003e\n\u003cp\u003eThis brought enormous benefits, because now I know that \u003cdel\u003eI need to listen to adults\u003c/del\u003e, I need to think in advance about the functionality that would be nice to have, and review other people’s projects to understand what I need to bring into my own one.\u003c/p\u003e\n\u003cp\u003eAfter several iterations and incorporating a feature to notify users once their journal entry is ready, the app transformed from a personal tool into something I believe could benefit others. Here\u0026rsquo;s a sneak peek at the app in action:\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eVideo of using the app is still in production, but it will be there soon\u003c/strong\u003e\u003c/p\u003e\n\u003ch5\u003eThroughout this journey, the learning curve was steep, but the personal and professional growth I experienced was immeasurable. I can say, that I became better at problem-solving, and broadened my technical skill set. Working with my mentor and seeking advice from peers in mobile development were crucial in allowing me to see my project from a different perspective. I had many hours of frustration and doubt, but overcoming these barriers was fulfilling.\u003c/h5\u003e\n","description":null,"image":null,"permalink":"https://mariavyso.github.io/posts/journaling_app/","title":"Journaling App"},{"content":"\u003ch5\u003eSummary: \u003cbr\u003eThis is a real-life case study about one of my work projects. Facing inefficiencies and limitations of the no-code tool we used, I built a Chrome extension to streamline our data analysis process and enhance error detection. \n\u003cbr\u003eThis tool reduces the time we spend on manual data checks and analysis by 25% per month, significantly boosting team productivity. \u003c/h5\u003e \n\u003cp\u003e\u003cbr\u003e\u003cstrong\u003eTools, I leaned on:\u003c/strong\u003e JS, Python, GCP.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e\u003cbr\u003eWorking in a small non-profit in a fast-paced environment usually puts you in a place where you need to choose between using an overpriced technical tool or a cheap tool. Choosing cheap doesn’t always mean that it suits your needs, but it always means that you need to do an additional job to make it work for you.\u003c/p\u003e\n\u003cp\u003eIn my job as a Technical and Data Director in the Localyst, I met this problem face to face. The main tool used in the company daily and made up 90% of the work was a no-code platform for assembling automatic bots for Facebook Messenger. Since the team had no developers and was a venture of a non-profit incubator that used the same platform, this was a logical decision. Before I was hired on the team, data analysis from the Facebook bot was done manually through this no-code platform. In one of the tabs, there was a database of users, and when building the bot, special attributes were assigned to each user who performed a certain action (clicked on a button and received an attribute).\u003c/p\u003e\n\u003cp\u003eSince the company was engaged in a narrative change about renewable energy, the bot was the main place for distributing content, and collecting and analyzing data was crucial in making decisions about the company\u0026rsquo;s further actions.\u003c/p\u003e\n\u003cp\u003eUnfortunately, life is more cunning than our plans, and while I was writing the same scripts in Python weekly, the platform we were using began to increase the number of errors rapidly. The main one was the lack of validation of the attribute field assigned to the user. Thus, one day we were unable to receive data on clicks in the broadcast we sent because the attribute contained a hidden symbol - line break. Of course, when checking the bot, this symbol was not visible and only after researching this error, I managed to find what was wrong by digging into the Chrome dev tool and the requests that were sent from the platform’s front end to their database.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cem\u003eIt is necessary to flag, that we made an attempt to contact support with this bug but, unfortunately, we were told that this was not a bug on their side, but our mistake, and I must prohibit the team from copy-pasting so this mistake won\u0026rsquo;t repeat. \u003cbr\u003e Copy-paste ban in 2023 lol\u003c/em\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eDue to this and other imperfections of the platform (for example, the lack of an API for pulling a database from the platform), I decided that I needed to build an extension for Chrome. Firstly, it had to automate routine daily work with scripts, and secondly, the platform’s interface had to be modified so that not only I can catch the errors, poking around in the Chrome dev tool, but also any member of the team who builds bot could do it simply. Since I was the one developer on the team, I needed to make this extension with minimal effort, since there was no time for thoughtful development and I had to continue to deliver the whole scope of my usual tasks.\u003c/p\u003e\n\u003cp\u003e\u003cbr\u003e\u003ch5\u003eI divided the task into 2 stages:\u003c/h5\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eAttribute verification. Insert a button into the interface and by clicking on it the attributes will be checked\u003c/li\u003e\n\u003cli\u003eAutomation of Analysis. Insert a button into the interface and by clicking on it the bot will be automatically analyzed and return to me CSV with this analysis.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cem\u003eLittle did I know, that at every stage new adventures await me.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eHowever, the impact of this extension was significant. It reduced the time spent on manual data analysis by 25% per month, increasing our team\u0026rsquo;s productivity and data accuracy.\u003c/p\u003e\n\u003cp\u003eThis project was not just about technical execution; it was a journey of constant learning and adaptation. I navigated through unexpected challenges, from deciphering a complex GraphQL database to addressing cross-origin resource sharing (CORS) issues, each obstacle providing valuable insights into the intricacies of extension development and data handling.\u003c/p\u003e\n\u003cp\u003eBut let\u0026rsquo;s dive deeper into each stage!\u003c/p\u003e\n\u003cbr\u003e\n\u003ch3 id=\"stage-1-attribute-verification\"\u003eStage 1: Attribute verification\u003c/h3\u003e\n\u003cp\u003ePreviously, in order to check each attribute of the bot, you needed to click on an average of 6-7 pages and check the block with the attribute on each one. In this case, an error in an attribute can be either in its name or in its value.\u003c/p\u003e\n\u003cp\u003e\u003cbr\u003e\u003cdiv style=\"position: relative; padding-bottom: 56.25%; overflow: hidden;\"\u003e\n\u003ciframe style=\"position: absolute; width: 100%; height: 100%;\" src=\"/images/chrome_extension_p1.mp4\" type=\"video/mp4\" frameborder=\"0\" allowfullscreen\u003e\u003c/iframe\u003e\u003c/p\u003e\n\u003c/div\u003e\n\u003cp\u003e\u003cbr\u003eSince I already knew where the attribute name and value are stored in the Chrome dev tool, and I needed to collect all the attributes for a specific block group (block group = 1 bot), I decided to try to pull them all using the API.\u003c/p\u003e\n\u003cp\u003eUnfortunately, such request was not written by the platform developers and I had to write it myself. The platform used a GraphQL database and it is necessary to say, that there are GraphQL databases that are well-written and take the common sense into account, but this was not our case.\u003c/p\u003e\n\u003cp\u003e\u003cbr\u003e\u003cimg src=\"/images/this_is_fine.jpg\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cbr\u003eAfter spending a couple of days learning how to write a request to the platform database, which began to be written when the company was a small service, but then they kept adding the new data in a random order, instead of rewriting it in a normal form, I managed to pull out all the bot attributes.\u003c/p\u003e\n\u003cp\u003eAfter that, I started the front end part - added a button next to each group of blocks in the interface and wrapped everything in an extension.\u003c/p\u003e\n\u003cp\u003eBy clicking on the button, we send a request to the platform server with the block group id and receive a CSV table with the columns “block name”, “attribute name”, and “attribute value”. If there is a hidden character in the name or value of an attribute, you can easily notice this in the table, go to the desired block and correct the attribute. For all my colleagues to be able to use the extension, I take their User ID from the Chrome dev tool when they first launch the extension.\u003c/p\u003e\n\u003cp\u003e\u003cbr\u003e\u003cdiv style=\"position: relative; padding-bottom: 56.25%; overflow: hidden;\"\u003e\n\u003ciframe style=\"position: absolute; width: 100%; height: 100%;\" src=\"/images/chrome_extension_p2.mp4\" type=\"video/mp4\" frameborder=\"0\" allowfullscreen\u003e\u003c/iframe\u003e\u003c/p\u003e\n\u003c/div\u003e\n\u003cbr\u003e\n\u003cbr\u003e\n\u003ch3 id=\"stage-2-automation-of-analysis\"\u003eStage 2. Automation of analysis\u003c/h3\u003e\n\u003cp\u003eBefore I completed the first stage of my Chrome extension, bot analysis was the same Python script with classes and functions, to which I passed different attributes based on the bot that we sent to subscribers. This routine and unpleasant work took time, and besides, thanks to Stage 1 of the extension, I already had a ready CSV table with attributes, so it seemed to me that adding this feature should be easy.\u003c/p\u003e\n\u003cp\u003e\u003cbr\u003e\u003cdiv style=\"width:70%;height:0;padding-bottom:57%;position:relative;\"\u003e\n    \u003cimg src=\"https://media.giphy.com/media/ceeN6U57leAhi/source.gif\" width=\"100%\" height=\"100%\" style=\"position:absolute\" frameBorder=\"0\"\u003e\n    \u003c/img\u003e\n  \u003c/div\u003e\n  \u003cp\u003e\u003ca href=\"https://giphy.com/gifs/ceeN6U57leAhi\"\u003evia GIPHY\u003c/a\u003e\u003c/p\u003e\u003c/p\u003e\n\u003cp\u003e\u003cbr\u003eTo carry out data analysis, previously I needed to manually download the database from the platform since the platform did not have an API for these purposes. So you can imagine how much time you’ll spend if you have a database of 200K+ users, and you need to wait for a request to an overcomplicated GraphQL database to save this database (an assumption that in 2023 no one needs the data backups should be illegal).\u003c/p\u003e\n\u003cp\u003eBut to automate the analysis, I need to have a fresh database daily, and this database should be in the company’s storage and it should get there automatically.\u003c/p\u003e\n\u003cp\u003eTo solve this problem, I used the good old Chome dev tools and reverse engineering to write the request that would work. Then, I put this request into the Google Function, so it receives the latest database and sends it to our Google Cloud Storage. Also, I added a Google Scheduler, that triggers the Function every day at 7 am.\u003c/p\u003e\n\u003cp\u003eWhen I thought about the architecture of this stage, I didn’t know that the main issue would wait for me at the end.\u003c/p\u003e\n\u003cp\u003eOn the front end side, I put a second button (next to the attribute collection button), by clicking on it the attributes are collected and sent to the script for analysis.\u003c/p\u003e\n\u003cp\u003eOn the backend side, the Python script should receive attributes, take the latest database backup from the Storage, conduct an analysis, and send an additional request to the platform to take the number of broadcast recipients from another part of its database (yes, unfortunately, this number doesn’t live in the main database) and collect the resulting analysis in a table, that should be familiar to stakeholders and the team and return the table in CSV form to the front end.\u003c/p\u003e\n\u003cp\u003eI decided to deploy this Python script into Google Functions because it was familiar and convenient, plus it was a logical step to simplify working with our Cloud Storage. The adventure began when I realized that I could not send anything from the Google Extension to a function due to CORS restrictions.\u003c/p\u003e\n\u003cp\u003e\u003cbr\u003e\u003cdiv style=\"width:70%;height:0;padding-bottom:57%;position:relative;\"\u003e\n    \u003cimg src=\"https://media.giphy.com/media/cNZmQ1qfjIZa4Xr3VE/source.gif\" width=\"100%\" height=\"100%\" style=\"position:absolute\" frameBorder=\"0\"\u003e\n    \u003c/img\u003e\n  \u003c/div\u003e\n  \u003cp\u003e\u003ca href=\"https://giphy.com/gifs/cNZmQ1qfjIZa4Xr3VE\"\u003evia GIPHY\u003c/a\u003e\u003c/p\u003e\u003c/p\u003e\n\u003cp\u003e\u003cbr\u003eI tried to Google and ChatGPT the issue and decided to use a background script, which operates and runs in a privileged context within the extension and is not subject to the same CORS restrictions as content scripts. To bridge the gap between the content script and the background script, I used \u003ccode\u003echrome.runtime.sendMessage\u003c/code\u003e, which helps to secure communication between different parts of the extension, besides handling the HTTP requests and responses.\u003c/p\u003e\n\u003cp\u003e\u003cbr\u003e\u003cimg src=\"/images/schema.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003ch6\u003eFinal extension architecture\u003c/h6\u003e\n\u003cp\u003e\u003cbr\u003e\u003ch5\u003eThe main insight here is that even with a lot of cool tools for data analysis and pipelines, we still have to reinvent the wheel.\u003c/h5\u003e\u003c/p\u003e\n\u003cp\u003ep.s. Currently, I am exploring ways to scale this solution. I already built Version 2, adding the integration of real-time data syncing with our Looker Dashboard, further streamlining our workflow. This experience has been pivotal in my professional growth and I’m eager to apply all the skills and insights from it in future challenges.\u003c/p\u003e\n","description":null,"image":null,"permalink":"https://mariavyso.github.io/posts/chrome_extension/","title":"Chrome Extension"},{"content":"\u003ch5\u003eSummary: \u003cbr\u003eThis is a real-life case study about how I built a Telegram bot with Python for a startup, diving into asynchronous programming and learning a ton along the way. The bot was used as a prototype for validating a startup's hypothesis.\u003c/h5\u003e\n\u003cp\u003e\u003cbr\u003e\u003cstrong\u003eTools, I leaned on:\u003c/strong\u003e BigQuery, Heroku, and the patience of my senior software-engineer mentor.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e\u003cbr\u003eI have a passion for helping startups. Once, I worked with a company, that wanted to build a platform, that used users’ input of zip code to show social, demographic, and economic data about this area. Of course, there must be more interesting data and insights in the future, but this task was pretty interesting for me.  After retrieving all the open data, and long hours of cleaning and transforming it, I finally had about 10 datasets that I put in the BigQuery.\u003c/p\u003e\n\u003cp\u003eThe pivotal task was presenting this data to non-technical stakeholders. My solution: a Telegram bot as a functional prototype for the envisioned platform. This interactive bot allowed stakeholders to understand and explore our data, offering a hands-on approach to hypothesis testing.\u003c/p\u003e\n\u003cp\u003eThe realization of this task was not so hard at first sight. First of all, I did some research about connecting the bot with BigQuery and learned how to create SQL queries inside the bot.\u003c/p\u003e\n\u003cp\u003eAt this time I never used asynchronous programming and thought that it was something that was far away from my experience (you know, how it feels when you a junior in any field). And of course, this time I came to the understanding that I can’t build the working system without it.\u003c/p\u003e\n\u003cp\u003eSo I found some examples of the async python bots on Github and started my journey. First of all, I made a simple user input + bot answer combination and when it worked, I started to add the queries in my main function that should run every query and return the information.\n\u003cbr\u003e\u003cbr\u003eIt leads me to this long read as an answer to user input of the zip code:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003ch5 id=\"postcode_bot\"\u003epostcode_bot:\u003c/h5\u003e\n\u003cp\u003eHere are what I found for Garden Suburb and 2019:\n\u003cbr\u003eTotal population for 2019 is: 17132;\n\u003cbr\u003ePredicted male population for 2019 is: 8098;\n\u003cbr\u003ePredicted female population for 2019 is: 8673;\n\u003cbr\u003ePredicted number of:\n\u003cbr\u003echildren (0-12): 15.51 %; teens (13-19): 7.24 %; adults (20-39): 26.28 %; mid-age adults (40-59): 27.49 %; seniors (60+): 23.48 %;\n\u003cbr\u003eThe following data is for 2021-2022:\n\u003cbr\u003eThe difference of house price in Barnet from may 2021 to may 2022: 11.4 % ;\n\u003cbr\u003eMedian household income for your postcode: £44394.20;\n\u003cbr\u003eThe number of households with:\n\u003cbr\u003e1 person : 27.71 %; 2 people : 30.25 %; 3 people : 15.97 %; 4 people : 15.61 %; 5 people : 7.26 %; 6 people : 2.5 %; 7 people : 0.54 %; 8+ people : 0.18 %;\n\u003cbr\u003eWorking households in Barnet:\n\u003cbr\u003eThe number of the working households: 56.59 %;\n\u003cbr\u003eThe number of the mixed (working+workless) households: 31.01 %;\n\u003cbr\u003eThe number of the workless households: 12.4 %;\n\u003cbr\u003e1 Household includes at least one person aged 16 to 64\n\u003cbr\u003eThe number of people, who lived in:\n\u003cbr\u003eowned outright residence: 42.4 %; owned with a mortgage or loan residence: 29.43 %; part owned and part rented residence: 0.2 %; social rented from local authority residence: 1.19 %; other social rented residence: 4.13 %; rented from private landlord or agency residence: 19.42 %; private rented as an employer of a household member residence: 0.14 %; private rented as a relative or friend of household member residence: 0.67 %; other private rented residence: 0.24 %; rent free residence: 2.18 %;\n\u003cbr\u003eSocial grade for this area:\n\u003cbr\u003eHigher and intermidiate managerial, administrative personal: 22 %;\n\u003cbr\u003eSupervisory or clerical and junior managerial, administrative or professional: 44 %;\n\u003cbr\u003eSkilled manual workers: 14 %;\n\u003cbr\u003eSemi and unskilled manual workers, casual or lowest grade workers, pensioners and others who depend on the state for their income: 20 %;\n\u003cbr\u003eSocial grade for this ward:\n\u003cbr\u003eHigher and intermidiate managerial, administrative personal: 53 %;\n\u003cbr\u003eSupervisory or clerical and junior managerial, administrative or professional: 30 %;\n\u003cbr\u003eSkilled manual workers: 7 %;\n\u003cbr\u003eSemi and unskilled manual workers, casual or lowest grade workers, pensioners and others who depend on the state for their income: 10 %;\n\u003cbr\u003eQualification level in the area. Percentage of people with:\n\u003cbr\u003eDegree level or above: 48 %;\n\u003cbr\u003e2+ A-levels or equivalent: 13 %;\n\u003cbr\u003eApprenticeship: Professional education: 2 %;\n\u003cbr\u003e5+ GCSEs or equivalent: 7 %;\n\u003cbr\u003e1-4 GCSEs or equivalent: 5 %;\n\u003cbr\u003eNo academic or professional qualifications: 6 %;\n\u003cbr\u003eOther Qualification: Vocational / Work-related Qualifications, Foreign Qualifications / Qualifications gained outside the UK: 19 %;\n\u003cbr\u003eQualification level in the ward. Percentage of people with:\n\u003cbr\u003eDegree level or above: 57 %;\n\u003cbr\u003e2+ A-levels or equivalent: 9 %;\n\u003cbr\u003eApprenticeship: Professional education: 1 %;\n\u003cbr\u003e5+ GCSEs or equivalent: 10 %;\n\u003cbr\u003e1-4 GCSEs or equivalent: 5 %;\n\u003cbr\u003eNo academic or professional qualifications: 8 %;\n\u003cbr\u003eOther Qualification: Vocational / Work-related Qualifications, Foreign Qualifications / Qualificationsgained outside the UK: 9 %;\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cbr\u003eAs you can see, it is a wall of text. Useful, but not exactly user-friendly.\n\u003cbr\u003e\u003cbr\u003eThat\u0026rsquo;s when I decided to add some visuals. I had to untangle my code to make it happen and spent five days rewriting everything. Moving from Tableau to generating visuals directly in the bot was tough but super satisfying.\n\u003cbr\u003e\u003cbr\u003eHere\u0026rsquo;s what the bot looks like now:\u003c/p\u003e\n\u003cp\u003e\u003cbr\u003e\u003cdiv style=\"position: relative; padding-bottom: 56.25%; overflow: hidden;\"\u003e\n\u003ciframe style=\"position: absolute; width: 100%; height: 100%;\" src=\"/images/bot_flow.mp4\" type=\"video/mp4\" frameborder=\"0\" allowfullscreen\u003e\u003c/iframe\u003e\u003c/p\u003e\n\u003c/div\u003e\n\u003cbr\u003e\n\u003cbr\u003eCurrently the bot is not online, as it was deployed with Heroku and now this company doesn’t have a free plan. I already decided what I’ll use instead of it, but I didn’t redeploy the bot yet.\n\u003cp\u003e\u003cbr\u003eLooking back, this project was a massive learning curve for me. It pushed me to explore new areas of programming and think about data in a more user-friendly way. The best part? Seeing non-techy people interact with the bot and have those \u0026lsquo;aha\u0026rsquo; moments.\n\u003cbr\u003eIn the future, I plan to redeploy the bot, further refining its functionality and exploring new data insights.\u003c/p\u003e\n\u003ch5\u003eIn the end, this wasn't just a tech project. It was about making data approachable, learning loads, and helping a startup take its first steps. \n\u003cbr\u003eAnd that's what I love about working in this space – it's always about more than just the code.\u003c/h5\u003e\n","description":null,"image":null,"permalink":"https://mariavyso.github.io/posts/postcode_bot/","title":"Postcode bot"}]